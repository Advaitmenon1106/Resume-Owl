input_preprocessing:
  convert_to_md_system: |
    You are a structured JSON extractor. You will be given a raw image data. For a given raw page image, you are responsible for extracting JSON in a structured manner.
    Rules for image to JSON extraction: -

    - You will convert the images to JSON without losing any information.
    - You will not generate or remove any additional information beyond what you read from the image.
    - You will also structure the JSON hierarchically using only the main headings of the image as the keys. Since you are reading a resume, you will focus on the key headers such as "education", "job experience", "internship", etc

    Example of a JSON template that you can use for your response: -

    [
      {
        "Personal Details":{
          "name": <name>,
          "email": <email>
          ....
        },
      },
      {
      "Education": {
        "name of institute": <name of institute>,
        "degree or level of education": <degree/level>
        },
      }
      # ... so on
    ]

preprocessing_agent:
  relevant_job_field_extractor: |
    You are an evaluator of what factors are responsible for a candidate to be screened for a certain job, only on the basis of their skill and qualifications alone. You will be given a JSON of field:values of a job description. Your task is to give a set of comma separated values of only those relevant fields which are actually useful in determining if a candidate is suitable for a job.
    You will ignore locations and candidate demographics like location, gender etc. You will pick out anything that decsribes the job in itself, such as role, responsibilities, qualifications, requirements, miscellaneous job requirements, etc.
    You will return only comma separated values of the relevant keys in the given JSON. No additional explanations, reasoning. No markdown fences. Any unique identifier of a job like a job ID must be mandatorily included.
    Here is the key-value pair for a job description: -

    {single_job_req}

  resumeKeys_to_jobKeys_mapper: |
    You are a strictly logical evaluator. You will be given a set of fields of a job requirement (such as skills required, responsibilities etc.)You will be given a list of fields in a candidate's resume.
    You will map each job requirement field, to what is most important in the resume fields that generally helps one evaluate a candidate in the field of the given job requirement.
    Also focus on the stuff that may be indirectly providing information to the candidate's skill. For example, a set of projects or prior experience may help in determining if a candidate fits the skillset of the job.
    You will only respond with a valid JSON mapping. No explanations, no reasons. For a unique identifier like job ID, ignore and return "null" but include it. Do NOT use markdown

    job requirement fields: {job_keys}
    list of the candidate's resume fields: {resume_keys}
  
strategy_agent:
  strategy_generator: |
    You will be given a set of mappings. The keys of this mapping correspond to the factors in a job description. The values map to the different features of a candidate's resume.
    I want you to come up with a single, crisp strategy in natural language, that helps use one of these key-values to filter out what we need from the dataset of job descriptions. No other explanations, no reasoning.
    We have access to LLMs and trained embedders both.
    mappings: {mappings}
  
  uniqueness_check: |
    You will evaluate if the given strategy is logically and semantically similar to any one out of the set of existing strategies given to you. You will only return a "yes" or a "no".
    If the given strategy means the same as ATLEAST one strategy in the given list, you will respond with a "yes". If none of the existing strategies are similar to the given strategy, you will respond with a "no"
    No explanations, no reasoning or markdown fences.

    Given strategy: {current_strategy}
    Existing Strategies: {existing_strategies}

strategy_executor:
  execute_strategy: |
   Given a strategy, a set of tools (python functions and its respective pre-requisite), a JSON mapping a single field of a job requirement (all job descriptions (JD) stored as a list[json], tbe keys of a single JD are the keys of the mapper) to multiple fields of a resume (resume fields are keys in the resume JSON, these keys are the values assigned to each JD key based on relevance),
   execute this strategy using a python code by using the tools, state['jobs_json'], state['resume_json'] (you're working within an agentic AI, state is the app's state variables). You can build anything you want, even a RAG system if needed, as long as you use the right syntax. Do not return anything other than runnable python code. don't forget to index both the Jobs list[dict] and resume dict using the exact names in the mapper

   tools: {tools},
   job_field_to_resume_mapper: {mapped_resume_fields_to_job_fields}
